# Utilisation des données
#
# Option A — Local :
#   On enregistre quelques pages résultats/annonces dans data/html/
#   puis on lance :  python src/parse_local_html.py
#   => Pas d'appel réseau pendant l'exécution, pratique pour la démo/CI.
#
# Option B — URLs (usage local, faible volume) :
#   On met jusqu’à ~20 URLs dans data/urls.txt (une par ligne),
#   puis on lance :  python src/spider.py
#   On laisse un délai entre chaque requête et on ne contourne rien.
#
# Remarques :
#   - Projet pédagogique, pas d’anti-bot, pas de proxy, pas de headless-stealth.
#   - On reste sur un volume très faible (≤20) pour ne pas charger le site.
#   - En CI/CD, on utilise l’Option A (fichiers locaux) pour éviter les requêtes live.

REQUEST_DELAY = 2.5  # secondes entre deux requêtes (Option B, local uniquement)
